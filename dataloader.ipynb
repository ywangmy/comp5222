{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Created on Fri Nov 24 2023 00:57:09\n",
    "# Author: Mukai (Tom Notch) Yu\n",
    "# Email: myual@connect.ust.hk\n",
    "# Affiliation: Hong Kong University of Science and Technology\n",
    "#\n",
    "# Copyright â’¸ 2023 Mukai (Tom Notch) Yu\n",
    "#\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from abc import ABC, abstractmethod\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from utils.files import read_file, print_dict\n",
    "from dataloader.feature_extractor import FeatureExtractor\n",
    "from dataloader.perspective_warper import PerspectiveWarper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: \n",
      "  epochs: 10.0\n",
      "  learning_rate: 0.0001\n",
      "  dataset: \n",
      "    batch_size: 32.0\n",
      "    COCO: \n",
      "      path: ./COCO2014/train2014\n",
      "      fraction: 0.001\n",
      "      resize: [640.0, 480.0]\n",
      "      fix_warp: false\n",
      "      shuffle: true\n",
      "    ScanNet: \n",
      "      path: ./ScanNet/train\n",
      "      fraction: 0.001\n",
      "      resize: [640.0, 480.0]\n",
      "      fix_warp: false\n",
      "      shuffle: true\n",
      "eval: \n",
      "  output_dir: ./dump_match_pairs/\n",
      "  eval_interval: 5.0\n",
      "  dataset: \n",
      "    batch_size: 32.0\n",
      "    COCO: \n",
      "      path: ./COCO2014/eval2014\n",
      "      fraction: 0.001\n",
      "      resize: [640.0, 480.0]\n",
      "      fix_warp: true\n",
      "      shuffle: true\n",
      "    ScanNet: \n",
      "      path: ./ScanNet/eval\n",
      "      fraction: 0.001\n",
      "      resize: [640.0, 480.0]\n",
      "      fix_warp: true\n",
      "      shuffle: true\n",
      "superglue: \n",
      "  num_layers: 3.0\n",
      "  sinkhorn_iterations: 10.0\n",
      "  match_threshold: 0.2\n",
      "  descriptor_dim: 256.0\n",
      "feature_extraction: \n",
      "  max_keypoints: 10.0\n",
      "  descriptor_dim: 256.0\n",
      "  extractor: \n",
      "    superpoint: \n",
      "      keypoint_threshold: 0.005\n",
      "      nms_radius: 4.0\n",
      "      match_threshold: 0.2\n",
      "      remove_borders: 4.0\n",
      "      model_weight_path: ./models/weights/superpoint_v1.pth\n",
      "perspective_warper: \n",
      "  max_warp_match_pixel_distance: 50.0\n",
      "  homography: \n",
      "    perturbation_threshold: 0.2\n",
      "visualize: true # Visualize the matches and dump the plots\n",
      "visualize_output_dir: ./dump_match_pairs/ # Output directory for the visualization\n"
     ]
    }
   ],
   "source": [
    "config = read_file(\"./configs/default.yaml\")\n",
    "print_dict(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_keypoints(image, keypoints, color=(0, 255, 0)):\n",
    "    # Create a copy of the input image to avoid modifying the original\n",
    "    image_with_keypoints = image.copy()\n",
    "\n",
    "    # Convert tensor keypoints to list of cv2.KeyPoint objects\n",
    "    cv_keypoints = [cv2.KeyPoint(x=kp[0], y=kp[1], size=10) for kp in keypoints.numpy()]\n",
    "\n",
    "    # Draw the keypoints on the copy of the image\n",
    "    image_with_keypoints = cv2.drawKeypoints(\n",
    "        image_with_keypoints,\n",
    "        cv_keypoints,\n",
    "        None,\n",
    "        color=color,\n",
    "        flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS,\n",
    "    )\n",
    "\n",
    "    return image_with_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class COCODataset(Dataset):\n",
    "    def __init__(self, config: dict, feature_extractor, perspective_warper):\n",
    "        self.config = config\n",
    "        self.path = config[\"path\"]\n",
    "        self.fraction = config[\"fraction\"]\n",
    "        self.resize = [int(dim) for dim in config[\"resize\"]]\n",
    "        self.fix_warp = config[\"fix_warp\"]\n",
    "        self.shuffle = config[\"shuffle\"]\n",
    "\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.perspective_warper = perspective_warper\n",
    "\n",
    "        self.files = []\n",
    "        # recursively walk though the directory\n",
    "        for root, _, files in os.walk(self.path):\n",
    "            for file in files:\n",
    "                if file.endswith(\".jpg\") or file.endswith(\".png\"):\n",
    "                    self.files.append(os.path.join(root, file))\n",
    "\n",
    "        # limit the number of files to self.fraction x total number of files\n",
    "        self.files = self.files[: int(len(self.files) * self.fraction)]\n",
    "\n",
    "        if self.fix_warp:\n",
    "            self.transforms = [\n",
    "                self.perspective_warper.generate_transform(*self.resize)\n",
    "                for _ in range(len(self.files))\n",
    "            ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        file = self.files[index]\n",
    "        image = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "        if self.resize is not None:\n",
    "            image = cv2.resize(image, self.resize)\n",
    "\n",
    "        width, height = image.shape\n",
    "\n",
    "        # Retrieve or generate transform\n",
    "        transform = (\n",
    "            self.transforms[index]\n",
    "            if self.fix_warp\n",
    "            else self.perspective_warper.generate_transform(width, height)\n",
    "        )\n",
    "\n",
    "        # Apply transform\n",
    "        image_novel = self.perspective_warper.warp_image_to_novel(image, transform)\n",
    "\n",
    "        (\n",
    "            keypoints_original,\n",
    "            descriptors_original,\n",
    "            confidence_score_original,\n",
    "        ) = self.feature_extractor(image)\n",
    "        (\n",
    "            keypoints_novel,\n",
    "            descriptors_novel,\n",
    "            confidence_score_novel,\n",
    "        ) = self.feature_extractor(image_novel)\n",
    "\n",
    "        keypoints_original_warped_to_novel = (\n",
    "            self.perspective_warper.warp_keypoints_to_novel(\n",
    "                keypoints_original, transform\n",
    "            )\n",
    "        )\n",
    "        keypoints_novel_warped_to_original = (\n",
    "            self.perspective_warper.warp_keypoints_to_original(\n",
    "                keypoints_novel, transform\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Compute distances between warped original keypoints and keypoints from the novel image\n",
    "        dists_original_to_novel = torch.cdist(\n",
    "            keypoints_original_warped_to_novel, keypoints_novel\n",
    "        )\n",
    "        dists_novel_to_original = torch.cdist(\n",
    "            keypoints_original, keypoints_novel_warped_to_original\n",
    "        )\n",
    "\n",
    "        # run linear_sum_assignment to find mutual nearest neighbors\n",
    "        (\n",
    "            row_index_original_to_novel,\n",
    "            col_index_original_to_novel,\n",
    "        ) = linear_sum_assignment(dists_original_to_novel)\n",
    "        (\n",
    "            row_index_novel_to_original,\n",
    "            col_index_novel_to_original,\n",
    "        ) = linear_sum_assignment(dists_novel_to_original)\n",
    "\n",
    "        # Initialize binary matrices with zeros\n",
    "        binary_matrix_original_to_novel = np.zeros(dists_original_to_novel.shape)\n",
    "        binary_matrix_novel_to_original = np.zeros(dists_novel_to_original.shape)\n",
    "\n",
    "        # Fill in the binary matrices based on the Hungarian algorithm results and the distance threshold\n",
    "        for r, c in zip(row_index_original_to_novel, col_index_original_to_novel):\n",
    "            if (\n",
    "                dists_original_to_novel[r, c]\n",
    "                <= self.perspective_warper.max_warp_match_pixel_distance\n",
    "            ):\n",
    "                binary_matrix_original_to_novel[r, c] = 1\n",
    "        for r, c in zip(row_index_novel_to_original, col_index_novel_to_original):\n",
    "            if (\n",
    "                dists_novel_to_original[r, c]\n",
    "                <= self.perspective_warper.max_warp_match_pixel_distance\n",
    "            ):\n",
    "                binary_matrix_novel_to_original[r, c] = 1\n",
    "\n",
    "        # Perform the element-wise logical AND operation to find mutual matches\n",
    "        mutual_matches = np.logical_and(\n",
    "            binary_matrix_original_to_novel, binary_matrix_novel_to_original.T\n",
    "        )\n",
    "\n",
    "        # Initialize the partial assignment matrix with zeros (no matches)\n",
    "        max_kp = self.feature_extractor.max_keypoints\n",
    "        partial_assignment_matrix = np.zeros(\n",
    "            (max_kp + 1, max_kp + 1), dtype=np.float32\n",
    "        )  # +1 for dustbin\n",
    "\n",
    "        # Copy the assignment matrix into the upper left corner of the partial assignment matrix\n",
    "        partial_assignment_matrix[\n",
    "            : mutual_matches.shape[0], : mutual_matches.shape[1]\n",
    "        ] = mutual_matches\n",
    "\n",
    "        # Accommodate the dustbins\n",
    "        partial_assignment_matrix[max_kp, :max_kp] = 1 - np.sum(\n",
    "            partial_assignment_matrix[:max_kp, :max_kp], axis=0\n",
    "        )  # Dustbin for novel keypoints\n",
    "        partial_assignment_matrix[:max_kp, max_kp] = 1 - np.sum(\n",
    "            partial_assignment_matrix[:max_kp, :max_kp], axis=1\n",
    "        )  # Dustbin for original keypoint\n",
    "\n",
    "        # Convert the partial_assignment_matrix with dustbins to a PyTorch tensor\n",
    "        partial_assignment_matrix = torch.from_numpy(partial_assignment_matrix)\n",
    "\n",
    "        # Pad keypoints, descriptors, and confidence scores with zeros\n",
    "        padded_keypoints_original = torch.cat(\n",
    "            (\n",
    "                keypoints_original,\n",
    "                torch.zeros(\n",
    "                    (max_kp - keypoints_original.shape[0], keypoints_original.shape[1])\n",
    "                ),\n",
    "            ),\n",
    "            dim=0,\n",
    "        )\n",
    "        padded_keypoints_novel = torch.cat(\n",
    "            (\n",
    "                keypoints_novel,\n",
    "                torch.zeros(\n",
    "                    (max_kp - keypoints_novel.shape[0], keypoints_novel.shape[1])\n",
    "                ),\n",
    "            ),\n",
    "            dim=0,\n",
    "        )\n",
    "        padded_descriptors_original = torch.cat(\n",
    "            (\n",
    "                descriptors_original,\n",
    "                torch.zeros(\n",
    "                    (max_kp - descriptors_novel.shape[0], descriptors_novel.shape[1])\n",
    "                ),\n",
    "            ),\n",
    "            dim=0,\n",
    "        )\n",
    "        padded_descriptors_novel = torch.cat(\n",
    "            (\n",
    "                descriptors_novel,\n",
    "                torch.zeros(\n",
    "                    (max_kp - descriptors_novel.shape[0], descriptors_novel.shape[1])\n",
    "                ),\n",
    "            ),\n",
    "            dim=0,\n",
    "        )\n",
    "        padded_confidence_scores_original = torch.cat(\n",
    "            (\n",
    "                confidence_score_original,\n",
    "                torch.zeros((max_kp - confidence_score_original.shape[0])),\n",
    "            ),\n",
    "            dim=0,\n",
    "        )\n",
    "        padded_confidence_scores_novel = torch.cat(\n",
    "            (\n",
    "                confidence_score_novel,\n",
    "                torch.zeros((max_kp - confidence_score_novel.shape[0])),\n",
    "            ),\n",
    "            dim=0,\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"image_original\": image,\n",
    "            \"image_novel\": image_novel,\n",
    "            \"keypoints_original\": padded_keypoints_original,\n",
    "            \"keypoints_novel\": padded_keypoints_novel,\n",
    "            \"descriptors_original\": padded_descriptors_original,\n",
    "            \"descriptors_novel\": padded_descriptors_novel,\n",
    "            \"confidence_scores_original\": padded_confidence_scores_original,\n",
    "            \"confidence_scores_novel\": padded_confidence_scores_novel,\n",
    "            \"partial_assignment_matrix\": partial_assignment_matrix,\n",
    "        }\n",
    "\n",
    "        keypoints_original_visualization = visualize_keypoints(\n",
    "            image, keypoints_original\n",
    "        )\n",
    "        plt.imshow(keypoints_original_visualization)\n",
    "        plt.show()\n",
    "\n",
    "        keypoints_original_warped_to_novel_visualization = visualize_keypoints(\n",
    "            image_novel, keypoints_original_warped_to_novel\n",
    "        )\n",
    "        plt.imshow(keypoints_original_warped_to_novel_visualization)\n",
    "        plt.show()\n",
    "\n",
    "        keypoints_novel_visualization = visualize_keypoints(\n",
    "            image_novel, keypoints_novel\n",
    "        )\n",
    "        plt.imshow(keypoints_novel_visualization)\n",
    "        plt.show()\n",
    "\n",
    "        keypoints_novel_warped_to_original_visualization = visualize_keypoints(\n",
    "            image, keypoints_novel_warped_to_original\n",
    "        )\n",
    "        plt.imshow(keypoints_novel_warped_to_original_visualization)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded SuperPoint model\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = FeatureExtractor(config[\"feature_extraction\"])\n",
    "perspective_warper = PerspectiveWarper(config[\"perspective_warper\"])\n",
    "\n",
    "coco_training_dataset = COCODataset(\n",
    "    config[\"train\"][\"dataset\"][\"COCO\"], feature_extractor, perspective_warper\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomnotch/mambaforge/envs/gnn-feature-matching/lib/python3.10/site-packages/torch/nn/functional.py:4296: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(coco_training_dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 11, 11])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"partial_assignment_matrix\"].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn-feature-matching",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
